{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP1RuHIF5Tfy7I0AU4n+y/b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nubiancodingdelight/ACS-Project-Repository-/blob/main/Generate_Matrix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebooks generates matrices as numpy arrays.\n",
        "Created By: Lorrayya Williams\n",
        "Updated On: 4/13/2025"
      ],
      "metadata": {
        "id": "UvXls329dons"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Set up\n"
      ],
      "metadata": {
        "id": "CuKb2-F_JAtm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ETdsGE0vcgEq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94d6548a-da0b-4689-82dc-3017cb12947d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#mounts google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set path\n",
        "%cd /content/drive/MyDrive/ACS_Research/VISDB_Data/"
      ],
      "metadata": {
        "id": "-I4DAI_3eAfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec492171-cc1f-4a31-a55e-1d4bc54de4c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ACS_Research/VISDB_Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSTALL"
      ],
      "metadata": {
        "id": "G--T3GMI_ORT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysam"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgQC1gd-_NO5",
        "outputId": "25251067-d010-4bc3-ea48-bfd50c4b6e04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pysam in /usr/local/lib/python3.11/dist-packages (0.23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "m0qTrxoW_6Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import subprocess\n",
        "import shlex\n",
        "import pysam\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import re\n",
        "import math\n",
        "import statistics as stat\n"
      ],
      "metadata": {
        "id": "IYWVvEG2_5qi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rgXbYXkQAACJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Cigar"
      ],
      "metadata": {
        "id": "oSrz1PWUJUVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_cigar(ref, seq):\n",
        "    cigar = []\n",
        "    count = 0\n",
        "    op = ''\n",
        "\n",
        "    for r, s in zip(ref, seq):\n",
        "        # Determine operation\n",
        "        if r == s and r != '-':\n",
        "            current_op = 'M'\n",
        "        elif r != s and r != '-' and s != '-':\n",
        "            current_op = 'X'\n",
        "        elif r == '-' and s != '-':\n",
        "            current_op = 'I'\n",
        "        elif s == '-' and r != '-':\n",
        "            current_op = 'D'\n",
        "        else:\n",
        "            continue  # skip if both are gaps\n",
        "\n",
        "        # Group by same operation\n",
        "        if current_op == op:\n",
        "            count += 1\n",
        "        else:\n",
        "            if op:\n",
        "                cigar.append(f\"{count}{op}\")\n",
        "            op = current_op\n",
        "            count = 1\n",
        "\n",
        "    if op:\n",
        "        cigar.append(f\"{count}{op}\")\n",
        "\n",
        "    return ''.join(cigar)\n",
        "\n",
        "# Example usage (aligned input)\n",
        "#ref = \"ACCGT-A\"\n",
        "#seq = \"AC-GTGA\"\n",
        "#print(generate_cigar(ref, seq))  # Output: 2=1D2=1I1=\n"
      ],
      "metadata": {
        "id": "zoFzrUZb6qCi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reverse Complete"
      ],
      "metadata": {
        "id": "DGJ0DrwUBOmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reverse_complement(seq):\n",
        "    complement = str.maketrans('ACGTNacgtn', 'TGCANtgcan')\n",
        "    return seq.translate(complement)[::-1]"
      ],
      "metadata": {
        "id": "knqs12-J-EjU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Bam from Sequence"
      ],
      "metadata": {
        "id": "nq4eKJq7JYVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pysam\n",
        "from pysam import AlignmentHeader, AlignedSegment\n",
        "def create_bam_from_sequence(output_bam_path, dna_sequence,ref_seq, reference_name, start_pos):\n",
        "  \"\"\"\n",
        "  Creates a BAM file from a DNA sequence and its coordinates.\n",
        "\n",
        "  Args:\n",
        "      output_bam_path (str): Path to save the BAM file (e.g., \"output.bam\").\n",
        "      dna_sequence (str): DNA sequence (e.g., \"ATCGATCG\").\n",
        "      reference_name (str): Reference sequence name (e.g., \"chr1\").\n",
        "      start_pos (int): 1-based start position on the reference.\n",
        "  \"\"\"\n",
        "  # 1. Create a BAM header\n",
        "  header = AlignmentHeader.from_references(\n",
        "      [reference_name],  # List of reference names\n",
        "      [1]  # Lengths of references\n",
        "      )\n",
        "\n",
        "  # 2. Open a BAM file for writing\n",
        "  with pysam.AlignmentFile(output_bam_path, \"wb\", header=header) as bam_file:\n",
        "    # 3. Create an aligned segment (read)\n",
        "    read = AlignedSegment(header)\n",
        "    read.query_name = \"read1\"  # Read ID\n",
        "    read.query_sequence = dna_sequence  # DNA sequence\n",
        "    read.flag = 0  # No flags set (0 means mapped)\n",
        "    read.reference_id = 0  # Index of reference in header (0 = first one)\n",
        "    read.reference_start = start_pos - 1  # 0-based position\n",
        "    read.mapping_quality = 60  # High mapping quality\n",
        "    read.cigarstring = generate_cigar(dna_sequence,ref_seq)  # CIGAR string (exact match)\n",
        "\n",
        "    # 4. Write the read to the BAM file\n",
        "    bam_file.write(read)\n",
        "\n",
        "     # Reverse strand read\n",
        "    read_rev = AlignedSegment(header)\n",
        "    read_rev.query_name = \"read2\"\n",
        "    rev_seq = reverse_complement(ref_seq[0:2000])\n",
        "    rev_ref = reverse_complement(ref_seq[0:2000])\n",
        "    read_rev.query_sequence = rev_seq\n",
        "    read_rev.flag = 16  # Reverse strand flag\n",
        "    read_rev.reference_id = 0\n",
        "    read_rev.reference_start = start_pos - 1\n",
        "    read_rev.mapping_quality = 60\n",
        "    read_rev.cigarstring = generate_cigar(rev_seq,rev_ref)\n",
        "    bam_file.write(read_rev)\n",
        "\n",
        "    return read, read_rev\n"
      ],
      "metadata": {
        "id": "53BK8xewyGHG"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Insertion Span"
      ],
      "metadata": {
        "id": "N2ZMJG4JJ9Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK WORK\n",
        "def insertion_span(vir_start, vir_end, ref_start, ref_end):\n",
        "  import math\n",
        "  diff = abs(vir_start- vir_end)\n",
        "  dir =  [0,1] if vir_start < vir_end else [1,0]\n",
        "  return min(ref_start, ref_end), min(ref_start, ref_end) -diff, dir"
      ],
      "metadata": {
        "id": "0rOwLQB2J7-Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate SAM file"
      ],
      "metadata": {
        "id": "ZP6x32b6AIAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Matrix Generator 1 -- DeepHBV\n"
      ],
      "metadata": {
        "id": "2exCcZa_Bdgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_virus(samfile,start, end):\n",
        "  for line in samfile:\n",
        "    line_list = str(line).split(\"\\t\")\n",
        "    CIGAR = line_list[5]\n",
        "    SEQ = line_list[9]\n",
        "    POS = line_list[3]\n",
        "    SEQ = line_list[9]\n",
        "    if int(POS) in range(start,end):\n",
        "      POS_SEQ.append(SEQ)\n",
        "    else:\n",
        "      NEG_SEQ.append(SEQ)\n",
        "  return POS_SEQ, NEG_SEQ\n"
      ],
      "metadata": {
        "id": "-vXgSMcd-ghb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import loadmat\n",
        "# from array import array\n",
        "# from util import seq_matrix\n",
        "\n",
        "def matrix_generator_uno(seq, isvirus=True):  # One Hot Encoding\n",
        "    seq_list = list(seq)\n",
        "    tensor = np.zeros((1, len(seq), 4))\n",
        "    if isvirus:\n",
        "      label = np.ones(1)\n",
        "    else:\n",
        "      label = np.zeros(1)\n",
        "      for s in seq:\n",
        "          if s == 'A' or s == 'a':\n",
        "              tensor[1][j] = [1, 0, 0, 0]\n",
        "          if s == 'T' or s == 't':\n",
        "              tensor[i][j] = [0, 1, 0, 0]\n",
        "          if s == 'C' or s == 'c':\n",
        "              tensor[i][j] = [0, 0, 1, 0]\n",
        "          if s == 'G' or s == 'g':\n",
        "              tensor[i][j] = [0, 0, 0, 1]\n",
        "          if s == 'N':\n",
        "              tensor[i][j] = [0, 0, 0, 0]\n",
        "    return tensor, label"
      ],
      "metadata": {
        "id": "_C1Rpc6h7JmQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Generator 2 -- Novel Matrix"
      ],
      "metadata": {
        "id": "Ew7WzqoiBw49"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#matrix row generator from CIGAR, SEQuence, Position of Insert\n",
        "def matrix_row(CIG, SEQ, POS, start, end, isVirus = True):\n",
        "  matrix_list= []\n",
        "  label_list =[]\n",
        "  bases = ['A','T','C','G']\n",
        "  seq_list= list(SEQ)\n",
        "  cigar_list = re.split(r'(\\d+)', CIG)[1::]\n",
        "  tensor= np.zeros((1,2000, 4))\n",
        "  if int(POS) in range(start,end) or isVirus:\n",
        "    label_list.append(1)\n",
        "  else:\n",
        "    label_list.append(0)\n",
        "\n",
        "  #print(len(seq_list))\n",
        "  #FIX LOOP\n",
        "  counter =0\n",
        "  if len(cigar_list) ==2:\n",
        "    #if it is a matched a sequence of 1's based on the base are added\n",
        "    if cigar_list[1] == 'M':\n",
        "      i= 0\n",
        "      for j in range(int(len(cigar_list[0]))):\n",
        "        num_list = [0,0,0,0]\n",
        "        try:\n",
        "          num_list[bases.index(seq_list[j])] = 1\n",
        "          #print(num_list)\n",
        "          print(j)\n",
        "          tensor[i][j]= num_list\n",
        "          #print(tensor[i][j])\n",
        "        except ValueError:\n",
        "          tensor[i][j]= num_list\n",
        "\n",
        "\n",
        "    else:\n",
        "      for j in range(len(seq_list)):\n",
        "        num_list = [0,0,0,0]\n",
        "\n",
        "#  return tensor, label_list\n",
        "\n",
        "  else:\n",
        "    length = 0\n",
        "    i = 0\n",
        "    for time in range(int(len(cigar_list)/2)):\n",
        "      if cigar_list[(2*time)+1] == 'M':\n",
        "        for j in range(length,length + int(cigar_list[(2*time)])):\n",
        "          num_list = [0,0,0,0]\n",
        "          try:\n",
        "            num_list[bases.index(seq_list[j])] = 1\n",
        "            #print(j)\n",
        "            counter += length\n",
        "            #print()\n",
        "            #print(j)\n",
        "            tensor[0][j]= num_list\n",
        "          except ValueError:\n",
        "            tensor[0][j]= num_list\n",
        "        length += int(cigar_list[(2*time)])\n",
        "        #print(length)\n",
        "  return tensor, label_list\n"
      ],
      "metadata": {
        "id": "fx6xyh275bOv"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import samefile\n",
        "def matrix_generator_dos (read1,read2, start, end, Matrix_Name ='Matrix_data', Label_Name='Label_data', save_file_path=os.getcwd()):\n",
        "  final_matrix = []\n",
        "  label_list = []\n",
        "  reads =[read1, read2]\n",
        "  for read in reads:\n",
        "    CIGAR = read.cigarstring\n",
        "    SEQ = read.query_sequence\n",
        "    POS = read.reference_start\n",
        "    final_matrix_temp, label_list_temp = matrix_row(CIGAR, SEQ, POS, start,end)\n",
        "    if len(final_matrix) == 0:\n",
        "      final_matrix = final_matrix_temp\n",
        "    else:\n",
        "      final_matrix = np.concatenate([final_matrix, final_matrix_temp])\n",
        "    label_list += label_list_temp\n",
        "\n",
        "  #saves matrix to specified path\n",
        "  os.chdir(save_file_path)\n",
        "  Data = np.asarray(final_matrix)\n",
        "  Label = np.asarray(label_list)\n",
        "  return Data, Label"
      ],
      "metadata": {
        "id": "LgfTPG5OO7zY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matrix Generator 3 -- 3D Matrix\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "wgsWjkESB0Bs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mapping_list(read1,read2, int_start, int_end, direction):\n",
        "  reads = [read1, read2]\n",
        "  mapping_list = []\n",
        "  for ind in range(len(reads)):\n",
        "    CIGAR = re.split(r'(\\d+)', reads[ind].cigarstring)[1::]\n",
        "    SEQ =  list(reads[ind].query_sequence)\n",
        "    POS = int(reads[ind].reference_start)\n",
        "    DIR = direction[ind]\n",
        "\n",
        "    COUNT= 0\n",
        "    print(len(SEQ))\n",
        "    print(CIGAR)\n",
        "    if len(CIGAR) ==2:\n",
        "    #if it is a matched a sequence of 1's based on the base are added\n",
        "      if CIGAR[1] == 'M':\n",
        "        mat = 1\n",
        "        for i in range(len(SEQ)):\n",
        "          mapping_list.append([SEQ[i], mat, int(POS) + i ,DIR, COUNT])\n",
        "          if dir ==0:\n",
        "            POS +=1\n",
        "          else: POS -=1\n",
        "      else:\n",
        "        mat=0\n",
        "        for i in range(len(SEQ)):\n",
        "          mapping_list.append([SEQ[i], mat, int(POS) + i ,DIR, COUNT])\n",
        "          if dir ==0:\n",
        "            POS +=1\n",
        "          else: POS -=1\n",
        "    else:\n",
        "      length = 0\n",
        "      i = 0\n",
        "      for time in range(int(len(CIGAR)/2)):\n",
        "        if CIGAR[(2*time)+1] == 'M':\n",
        "          mat =1\n",
        "          for j in range(length,length + int(CIGAR[(2*time)])):\n",
        "            mapping_list.append([SEQ[j], mat, int(POS) + i ,DIR, COUNT])\n",
        "            if dir ==0:\n",
        "              POS +=1\n",
        "            else: POS -=1\n",
        "          length += int(CIGAR[(2*time)])\n",
        "        else:\n",
        "          mat =0\n",
        "          for j in range(length,length + int(CIGAR[(2*time)])):\n",
        "            mapping_list.append([SEQ[j], mat, int(POS) + i ,DIR, COUNT])\n",
        "            if dir ==0:\n",
        "              POS +=1\n",
        "            else: POS -=1\n",
        "            i += 1\n",
        "          length += int(CIGAR[(2*time)])\n",
        "        COUNT += 1\n",
        "  length = len(mapping_list)\n",
        "  print(length)\n",
        "  #order a list lists\n",
        "  df = pd.DataFrame(mapping_list, columns = ['Base', 'Match', 'Position', 'Direction', 'Row_count'])\n",
        "  print(\"Length of df\" + str(len(df)))\n",
        "  df = df.sort_values(by=['Position'])\n",
        "  #df = df.reset_index(drop=True)\n",
        "  #df = df.tail(-1).drop_duplicates()\n",
        "  #df = df.reset_index(drop=True)\n",
        "  three_five = df[df['Direction'] ==0]\n",
        "  five_three = df[df['Direction'] ==1]\n",
        "  return df, three_five, five_three"
      ],
      "metadata": {
        "id": "PqoF2HTuFYew"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_generator_tres(read1, read2, int_start, int_end, direction, isVirus =True, Matrix_Name ='Matrix_data', Label_Name='Label_data', save_file_path=os.getcwd()):\n",
        "  df, three_five, five_three = generate_mapping_list(read1,read2, int_start, int_end, direction)\n",
        "  #create tensor\n",
        "  print(\"-----\")\n",
        "  print(len(df))\n",
        "  print(len(five_three))\n",
        "  print(len(three_five))\n",
        "  print(\"-----\")\n",
        "  tensor = np.zeros((1,2000,  4))\n",
        "  label = np.zeros(len(df))\n",
        "  label_list= [0] * len(df)\n",
        "\n",
        "  col_count = 0\n",
        "  curr_pos = 0\n",
        "  end_pos = 0\n",
        "  bases = ['A','T','C','G']\n",
        "  match_dict ={'A':'T', 'T':'A', 'C':'G', 'G':'C'}\n",
        "  row = 0\n",
        "  for col_count in range(1,len(df)):\n",
        "    curr_pos = df['Position'][row]\n",
        "    #print(df['Base'][col_count])\n",
        "  #3' -->5' Direction\n",
        "\n",
        "    if df['Direction'][row] == 0:\n",
        "      #checks to see if it matches with alignment genome\n",
        "      if three_five['Base'][row//2] in bases and three_five['Match'][row] == 1:\n",
        "        tensor[row][col_count][bases.index(df['Base'][row].upper())] = 1\n",
        "\n",
        "        #checks if the bases match with each other\n",
        "        #print(df[df['Position']== df['Position'][row]].Base.values[0])\n",
        "        if five_three[five_three['Position']== three_five['Position'][row//2]]['Base'].upper() == match_dict[str(three_five['Base'][row//2]).upper()]:\n",
        "          tensor[row][col_count][bases.index(df['Base'][row//2].upper())] =3\n",
        "\n",
        "      #checks if it matches with each other but not with alignment genome\n",
        "      elif  str(five_three[five_three['Position']== three_five['Position'][row//2]].Base).upper() == match_dict[str(three_five['Base'][row//2]).upper()]:\n",
        "          tensor[row][col_count][bases.index(df['Base'][row//2].upper())]=2\n",
        "\n",
        "  #5'-->3' Direction\n",
        "    else:\n",
        "      #checks to see if it matches with alignment genome\n",
        "      if five_three['Base'][row] in bases and five_three['Match'][row//2] == 1:\n",
        "        tensor[row][col_count][bases.index(five_three['Base'][row//2].upper())] = 1\n",
        "\n",
        "        #checks if the bases match with each other\n",
        "        #print( match_dict[df['Base'][row]])\n",
        "\n",
        "        #print(df[df['Position']== df['Position'][row]].Base.item())\n",
        "        if three_five[three_five['Position']== five_three['Position'][row//2]].Base.upper() == match_dict[str(five_three['Base'][row//2]).upper()]:\n",
        "          tensor[row][col_count][bases.index(df['Base'][row//2].upper())] =3\n",
        "\n",
        "      #checks if it matches with each other but not with alignment genome\n",
        "      elif  str(five_three[five_three['Position']== three_five['Position'][row//2]].Base).upper() == match_dict[str(three_five['Base'][row//2]).upper()]:\n",
        "          tensor[row][col_count][bases.index(df['Base'][row//2].upper())]=2\n",
        "  if curr_pos in range(int_start,int_end) or isVirus:\n",
        "    label[row] =1\n",
        "  else:\n",
        "    label[row] =0\n",
        "  return tensor, label\n",
        "'''\n",
        "    if curr_pos == end_pos:\n",
        "      if int(curr_pos) in range(int_start,int_end):\n",
        "        label_list.append(1)\n",
        "      else:\n",
        "        label_list.append(0)\n",
        "      end_pos +=75\n",
        "      col_count +=1\n",
        "      if col_count == 150:\n",
        "        col_count =0\n",
        "\n",
        "    elif end_pos == 0:\n",
        "      end_pos= curr_pos +75\n",
        "      if int(curr_pos) in range(int_start,int_end):\n",
        "        label_list.append(1)\n",
        "      else:\n",
        "        label_list.append(0)\n",
        " '''\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "toCzHoNZ7fy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "364793b3-ce29-4a8e-fb0c-c7fe0b355e4e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n    if curr_pos == end_pos:\\n      if int(curr_pos) in range(int_start,int_end):\\n        label_list.append(1)\\n      else:\\n        label_list.append(0)\\n      end_pos +=75\\n      col_count +=1\\n      if col_count == 150:\\n        col_count =0\\n\\n    elif end_pos == 0:\\n      end_pos= curr_pos +75\\n      if int(curr_pos) in range(int_start,int_end):\\n        label_list.append(1)\\n      else:\\n        label_list.append(0)\\n '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TESTING"
      ],
      "metadata": {
        "id": "MMfPe6JNESJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load hbv data\n",
        "import pandas as pd\n",
        "hbv_data = pd.read_csv('Spliced_Data_HBV.csv')\n",
        "hbv_data = hbv_data.iloc[1:]\n",
        "hbv_data = hbv_data[hbv_data['spliced_seq'].str.len() == 2000]"
      ],
      "metadata": {
        "id": "eO_92ZIaFlSm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing\n",
        "matrix, label =matrix_generator_uno(str(hbv_data['spliced_seq'][1]), True)\n",
        "print(matrix.shape)\n",
        "print(label.shape)"
      ],
      "metadata": {
        "id": "rsuDmbqv8Nxx",
        "outputId": "dd926c2a-15bd-4c27-f4ef-dcec89d1ec1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2000, 4)\n",
            "(1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing Code\n",
        "read1, read2 = create_bam_from_sequence('/content/drive/MyDrive/ACS_Research/VISDB_Data/Aligned_Sequences/HBV/HBV2.bam',hbv_data['spliced_seq'][2], hbv_data['human_ref_sequence'][2], 'hg19', hbv_data['begin_breakpoint'][2])\n",
        "start,end,direction = insertion_span(hbv_data['begin_ref'][2], hbv_data['stop_ref'][2], hbv_data['begin_breakpoint'][2], hbv_data['stop_breakpoint'][2])\n",
        "Data2,Label2 =matrix_generator_dos (read1, read2, start, end, Matrix_Name ='HBV_Matrix_2_data', Label_Name='HBV_Label_2_data', save_file_path=os.getcwd())\n",
        "print(Data2.shape)\n",
        "print(Label2.shape)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lL63zojYAM1H",
        "outputId": "5b293b51-19a2-4e8d-bba2-690caab1999f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "(2, 2000, 4)\n",
            "(2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "read1, read2 = create_bam_from_sequence('/content/drive/MyDrive/ACS_Research/VISDB_Data/Aligned_Sequences/HBV/HBV2.bam',hbv_data['spliced_seq'][2], hbv_data['human_ref_sequence'][2], 'hg19', hbv_data['begin_breakpoint'][2])\n",
        "start,end,direction = insertion_span(hbv_data['begin_ref'][2], hbv_data['stop_ref'][2], hbv_data['begin_breakpoint'][2], hbv_data['stop_breakpoint'][2])\n",
        "Data3,Label3 =matrix_generator_tres (read1, read2, start, end, direction,Matrix_Name ='HBV_Matrix_2_data', Label_Name='HBV_Label_2_data', save_file_path=os.getcwd())\n",
        "print(Data3.shape)\n",
        "print(Label3.shape)"
      ],
      "metadata": {
        "id": "N0UmfQJIFiE6",
        "outputId": "eaf8e0b6-98fb-4bf2-8c3a-a943d69336f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n",
            "['75', 'X', '1', 'M', '3', 'X', '1', 'M', '42', 'X', '1', 'M', '1', 'X', '1', 'M', '4', 'X', '1', 'M', '1', 'X', '1', 'M', '142', 'X', '3', 'M', '1', 'X', '1', 'M', '1', 'X', '1', 'M', '2', 'X', '1', 'M', '1', 'X', '1', 'M', '8', 'X', '2', 'M', '5', 'X', '1', 'M', '5', 'X', '1', 'M', '5', 'X', '1', 'M', '11', 'X', '1', 'M', '2', 'X', '1', 'M', '2', 'X', '1', 'M', '1', 'X', '1', 'M', '1', 'X', '2', 'M', '4', 'X', '1', 'M', '1', 'X', '2', 'M', '1', 'X', '1', 'M', '1', 'X', '2', 'M', '1', 'X', '2', 'M', '1', 'X', '1', 'M', '3', 'X', '1', 'M', '6', 'X', '1', 'M', '3', 'X', '1', 'M', '31', 'X', '3', 'M', '2', 'X', '1', 'M', '4', 'X', '1', 'M', '2', 'X', '1', 'M', '14', 'X', '1', 'M', '1', 'X', '1', 'M', '7', 'X', '1', 'M', '5', 'X', '1', 'M', '6', 'X', '1', 'M', '9', 'X', '2', 'M', '2', 'X', '1', 'M', '2', 'X', '1', 'M', '1', 'X', '2', 'M', '2', 'X', '2', 'M', '4', 'X', '2', 'M', '1', 'X', '2', 'M', '5', 'X', '2', 'M', '3', 'X', '1', 'M', '2', 'X', '1', 'M', '2', 'X', '3', 'M', '3', 'X', '1', 'M', '5', 'X', '1', 'M', '4', 'X', '1', 'M', '3', 'X', '1', 'M', '20', 'X', '2', 'M', '2', 'X', '1', 'M', '4', 'X', '1', 'M', '5', 'X', '1', 'M', '8', 'X', '1', 'M', '1', 'X', '1', 'M', '3', 'X', '3', 'M', '1', 'X', '1', 'M', '1', 'X', '3', 'M', '4', 'X', '1', 'M', '1', 'X', '1', 'M', '170', 'X', '1', 'M', '2', 'X', '2', 'M', '3', 'X', '1', 'M', '3', 'X', '1', 'M', '6', 'X', '1', 'M', '7', 'X', '2', 'M', '385', 'X', '1', 'M', '1', 'X', '1', 'M', '2', 'X', '1', 'M', '2', 'X', '4', 'M', '6', 'X', '1', 'M', '2', 'X', '2', 'M', '2', 'X', '1', 'M', '3', 'X', '2', 'M', '1', 'X', '3', 'M', '6', 'X', '2', 'M', '12', 'X', '1', 'M', '8', 'X', '1', 'M', '3', 'X', '1', 'M', '1', 'X', '1', 'M', '4', 'X', '1', 'M', '1', 'X', '1', 'M', '3', 'X', '1', 'M', '1', 'X', '1', 'M', '9', 'X', '1', 'M', '6', 'X', '1', 'M', '3', 'X', '1', 'M', '191', 'X', '1', 'M', '1', 'X', '1', 'M', '4', 'X', '1', 'M', '2', 'X', '1', 'M', '7', 'X', '1', 'M', '1', 'X', '2', 'M', '1', 'X', '1', 'M', '3', 'X', '1', 'M', '1', 'X', '1', 'M', '3', 'X', '1', 'M', '6', 'X', '5', 'M', '1', 'X', '1', 'M', '195', 'X', '1', 'M', '1', 'X', '1', 'M', '5', 'X', '2', 'M', '6', 'X', '1', 'M', '1', 'X', '1', 'M', '4', 'X', '1', 'M', '6', 'X', '3', 'M', '7', 'X', '2', 'M', '2', 'X', '1', 'M', '5', 'X', '2', 'M', '200', 'X', '1', 'M', '2', 'X', '1', 'M', '6', 'X', '1', 'M', '1', 'X', '1', 'M', '2', 'X', '1', 'M', '1', 'X', '1', 'M', '9', 'X', '1', 'M', '3', 'X', '1', 'M', '2', 'X', '2', 'M']\n",
            "2000\n",
            "['2000', 'M']\n",
            "4000\n",
            "Length of df4000\n",
            "-----\n",
            "4000\n",
            "2000\n",
            "2000\n",
            "-----\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-cb132795a2ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_bam_from_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/ACS_Research/VISDB_Data/Aligned_Sequences/HBV/HBV2.bam'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhbv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'spliced_seq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhbv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'human_ref_sequence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'hg19'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhbv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'begin_breakpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minsertion_span\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhbv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'begin_ref'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhbv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop_ref'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhbv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'begin_breakpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhbv_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stop_breakpoint'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mData3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLabel3\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mmatrix_generator_tres\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mread1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mread2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMatrix_Name\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'HBV_Matrix_2_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabel_Name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'HBV_Label_2_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLabel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-12f87149d5e6>\u001b[0m in \u001b[0;36mmatrix_generator_tres\u001b[0;34m(read1, read2, int_start, int_end, direction, isVirus, Matrix_Name, Label_Name, save_file_path)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m       \u001b[0;31m#checks if it matches with each other but not with alignment genome\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0;32melif\u001b[0m  \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfive_three\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfive_three\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0mthree_five\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmatch_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthree_five\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m           \u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_count\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbases\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Base'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcurr_pos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint_end\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misVirus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HBV"
      ],
      "metadata": {
        "id": "7Jxu7cg2I-UH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Bam File"
      ],
      "metadata": {
        "id": "tXoCbFSHJDH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load hbv data\n",
        "import pandas as pd\n",
        "hbv_data = pd.read_csv('Spliced_Data_HBV.csv')\n",
        "hbv_data.head()"
      ],
      "metadata": {
        "id": "P9ZMnmMX1mDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hbv_data = hbv_data.iloc[1:]\n",
        "hbv_data = hbv_data[hbv_data['spliced_seq'].str.len() == 2000]"
      ],
      "metadata": {
        "id": "F9vOclz84wFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK WORK\n",
        "def insertion_span(vir_start, vir_end, ref_start, ref_end):\n",
        "  import math\n",
        "  diff = abs(vir_start- vir_end)\n",
        "  dir =  0 if vir_start < vir_end else 1\n",
        "  return min(ref_start, ref_end), min(ref_start, ref_end) -diff, dir"
      ],
      "metadata": {
        "id": "h3Vzx0cyLM7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "##TROUBLESHOOT####################################################\n",
        "for index, row in hbv_data.iterrows():\n",
        "  try:\n",
        "    bam_file_path = '/content/drive/MyDrive/ACS_Research/VISDB_Data/Aligned_Sequences/'  +str(row['virus'])+str(index)+'.bam' # Changed to .bam\n",
        "    read1, read2 = create_bam_from_sequence(bam_file_path,row['spliced_seq'], row['human_ref_sequence'], 'hg19', row['begin_breakpoint'])\n",
        "\n",
        "    start,end,direction = insertion_span(row['begin_ref'], row['stop_ref'], row['begin_breakpoint'], row['stop_breakpoint'])\n",
        "\n",
        "    #generate matrix 1\n",
        "    Data1, Label1=matrix_generator_uno(row['spliced_seq'])))\n",
        "\n",
        "    #save matrix 1 output\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HBV/Experiment_1/'+str(row['virus'])+str(index)+'_Matrix_data.npy', Data1)\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HBV/Experiment_1/'+str(row['virus'])+str(index)+'_Label_data.npy', Label1)\n",
        "\n",
        "  #generate matrix 2\n",
        "    Data2,Label2 =matrix_generator_dos (read1, read2, start, end, Matrix_Name ='HBV_Matrix_2_data', Label_Name='HBV_Label_2_data', save_file_path=os.getcwd())\n",
        "\n",
        "  #save generated data\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HBV/Experiment_2/'+str(row['virus'])+str(index)+'_Matrix_data.npy', Data2)\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HBV/Experiment_2/'+str(row['virus'])+str(index)+'_Label_data.npy', Label2)\n",
        "\n",
        "\n",
        "  #generate matrix 3\n",
        "    #Data3,Label3 =matrix_generator_tres(read1,read2, start, end, direction, Matrix_Name ='Matrix_data', Label_Name='Label_data', save_file_path=os.getcwd())\n",
        "\n",
        "    #save matrix\n",
        "    #np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HBV/Experiment_3/'+str(row['virus'])+str(index)+'_Matrix_data.npy', Data3)\n",
        "    #np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HBV/Experiment_3/'+str(row['virus'])+str(index)+'_Label_data.npy', Label3)\n",
        "  except:\n",
        "    print(row['viral_seq'])\n",
        "    pass"
      ],
      "metadata": {
        "id": "lh-qrKA1169f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HPV"
      ],
      "metadata": {
        "id": "K_TiNpIFnnzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load hbv data\n",
        "import pandas as pd\n",
        "hpv_data = pd.read_csv('Spliced_Data_HPV.csv')\n",
        "hpv_data = hpv_data[hpv_data['spliced_seq'].str.len() == 2000]\n",
        "hpv_data.head()"
      ],
      "metadata": {
        "id": "AsSxSguwnsMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##TROUBLESHOOT####################################################\n",
        "for index, row in hpv_data.iterrows():\n",
        "  try:\n",
        "    bam_file_path = '/content/drive/MyDrive/ACS_Research/VISDB_Data/Aligned_Sequences/'  +str(row['virus'])+str(index)+'.bam' # Changed to .bam\n",
        "    read1, read2 = create_bam_from_sequence(bam_file_path,row['spliced_seq'], row['human_ref_sequence'], 'hg19', row['begin_breakpoint'])\n",
        "\n",
        "    start,end,direction = insertion_span(row['begin_ref'], row['stop_ref'], row['begin_breakpoint'], row['stop_breakpoint'])\n",
        "\n",
        "    #generate matrix 1\n",
        "    Data1, Label1=matrix_generator_uno(row['viral_seq'], len(str(row['viral_seq'])))\n",
        "\n",
        "    #save matrix 1 output\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HPV/Experiment_1/'+str(row['virus'])+str(index)+'_Matrix_data.npy', Data1)\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HPV/Experiment_1/'+str(row['virus'])+str(index)+'_Label_data.npy', Label1)\n",
        "\n",
        "  #generate matrix 2\n",
        "    Data2,Label2 =matrix_generator_dos (read1, read2, start, end, Matrix_Name ='HBV_Matrix_2_data', Label_Name='HBV_Label_2_data', save_file_path=os.getcwd())\n",
        "\n",
        "  #save generated data\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HPV/Experiment_2/'+str(row['virus'])+str(index)+'_Matrix_data.npy', Data2)\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HPV/Experiment_2/'+str(row['virus'])+str(index)+'_Label_data.npy', Label2)\n",
        "\n",
        "\n",
        "  #generate matrix 3\n",
        "    Data3,Label3 =matrix_generator_tres(read1,read2, start, end, direction, Matrix_Name ='Matrix_data', Label_Name='Label_data', save_file_path=os.getcwd())\n",
        "\n",
        "    #save matrix\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HPV/Experiment_3/'+str(row['virus'])+str(index)+'_Matrix_data.npy', Data3)\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/HPV/Experiment_3/'+str(row['virus'])+str(index)+'_Label_data.npy', Label3)\n",
        "  except:\n",
        "    print(row['viral_seq'])\n",
        "    pass"
      ],
      "metadata": {
        "id": "LHWb6PBfn0CZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference Data\n"
      ],
      "metadata": {
        "id": "mxApLZW-amlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load hbv data\n",
        "import pandas as pd\n",
        "ref_data = pd.read_csv('Spliced_Data_Reference.csv')\n",
        "ref_data.head()"
      ],
      "metadata": {
        "id": "HSQ5kHBRa3bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: remove first row from hbv_Data\n",
        "ref_data = ref_data.iloc[1:]\n"
      ],
      "metadata": {
        "id": "7p1O7g-Ia3bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##TROUBLESHOOT####################################################\n",
        "for index, row in ref_data.iterrows():\n",
        "  try:\n",
        "    bam_file_path = '/content/drive/MyDrive/ACS_Research/VISDB_Data/Aligned_Sequences/'+str(row['chromosome'])+'_'+str(index)+'.bam' # Changed to .bam\n",
        "    #print(row['human_ref_sequence'])\n",
        "    read1, read2 = create_bam_from_sequence(bam_file_path,row['human_ref_sequence'], row['human_ref_sequence'], 'hg19', row['start'])\n",
        "\n",
        "    #start,end,direction = insertion_span(row['begin_ref'], row['stop_ref'], row['begin_breakpoint'], row['stop_breakpoint'])\n",
        "\n",
        "    #generate matrix 1\n",
        "    #Data1, Label1=matrix_generator_uno(row['human_ref_sequence'], len(str(row['human_ref_sequence'])))\n",
        "\n",
        "    #save matrix 1 output\n",
        "    #np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/References/Experiment_1/'+str(row['chromosome'])+'_'+str(index)+'_Matrix_data.npy', Data1)\n",
        "    #np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/References/Experiment_1/'+str(row['chromosome'])+'_'+str(index)+'_Label_data.npy', Label1)\n",
        "\n",
        "  #generate matrix 2\n",
        "    #Data2,Label2 =matrix_generator_dos (read1, read2, row['start'], row['stop'], Matrix_Name ='HBV_Matrix_2_data', Label_Name='HBV_Label_2_data', save_file_path=os.getcwd())\n",
        "\n",
        "  #save generated data\n",
        "    #np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/References/Experiment_2/'+str(row['chromosome'])+'_'+str(index)+'_Matrix_data.npy', Data2)\n",
        "    #np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/References/Experiment_2/'+str(row['chromosome'])+'_'+str(index)+'_Label_data.npy', Label2)\n",
        "\n",
        "\n",
        "  #generate matrix 3\n",
        "    Data3,Label3 =matrix_generator_tres(read1,read2, row['start'], row['stop'], 0, Matrix_Name ='Matrix_data', Label_Name='Label_data', save_file_path=os.getcwd())\n",
        "\n",
        "    #save matrix\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/References/Experiment_3/'+str(row['chromosome'])+'_'+str(index)+'_Matrix_data.npy', Data3)\n",
        "    np.save('/content/drive/MyDrive/ACS_Research/VISDB_Data/Matrices/References/Experiment_3/'+str(row['chromosome'])+'_'+str(index)+'_Label_data.npy', Label3)\n",
        "  except:\n",
        "    print(row['human_ref_sequence'])"
      ],
      "metadata": {
        "id": "dSyUWZK6hlME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Matrix Creation"
      ],
      "metadata": {
        "id": "qefNqbq3530r"
      }
    }
  ]
}